{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python语言与经济大数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4讲 文本分析入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#郭峰（上海财经大学投资系副教授）\n",
    "#Email：guo.feng@mail.sufe.edu.cn\n",
    "#2019-01-21\n",
    "#本讲目录\n",
    "#4.1 文本字数统计\n",
    "#4.2 文档格式转换(doc\\docx转换成txt）\n",
    "#4.3 字频统计\n",
    "#4.4 关键词的提取与统计\n",
    "#4.5 文本编码格式\n",
    "#4.6 jieba分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 文本字数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt字数统计，一个文件\n",
    "path='D:/python/郭峰Python讲义/数据与结果/'\n",
    "f= open(path+\"政府工作报告2018.txt\",\"r\")\n",
    "report=f.read()  \n",
    "report_len = len(report)                \n",
    "line_num = report.count(\"\\n\")       #统计行数\n",
    "words_num = len(report.split())     #统计单词数,这个适合于英文文本，这里强行应用而已，将字符串按空格分割成一个list，统计list的长度\n",
    "print(\"字符数：%s,\\n行数:%s,\\n单词数量%s\"%(report_len,line_num,words_num))\n",
    "# 注：这样统计后得到的数字比word中显示的字数要多，估计是数字、英文字母的意思，word文本显示的字数，2010被算作1次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word文档字数统计,一个文件\n",
    "import docx\n",
    "\n",
    "path='D:/python/郭峰Python讲义/数据与结果/'\n",
    "wordtest=docx.Document(path+\"政府工作报告2018.docx\")  \n",
    "\n",
    "a=0\n",
    "for para in wordtest.paragraphs:   \n",
    "    a=a+len(para.text)            #目前只会按照段落一段段求字数，不知道是否有直接求字数的命令\n",
    "print(a)\n",
    "\n",
    "#这个统计出来的字数和上面那个txt文档又有所不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#字数统计,文件夹批量处理，txt格式\n",
    "import os\n",
    "path = \"D:/python/郭峰Python讲义/数据与结果/政府工作报告/\" #文件夹目录  \n",
    "path2 = \"D:/python/郭峰Python讲义/数据与结果/\" #结果目录  \n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "wnum={}   #定义一个空字典\n",
    "for file in files:    #遍历文件夹\n",
    "     #print(file)\n",
    "     if not os.path.isdir(file):      #判断是否是文件夹，不是文件夹才打开  \n",
    "          f = open(path+file,encoding='gbk',errors=\"replace\")     #打开文件  \n",
    "          try:\n",
    "                text=f.read()\n",
    "                file=file[:-4]\n",
    "                wnum[file]=len(text)     #一个字典\n",
    "          except:                        #try, except是查验错误的一种方式，正确的话就执行，错误的话，输出到底哪个错误了\n",
    "                print(file)\n",
    "#print(wnum)\n",
    "f = open(path2+\"city_wordnum.txt\", \"w+\")  #结果读入到一个txt文件当中\n",
    "f.write(\"city\"+\" \"+\"year\"+\" \"+\"wnum\"+\"\\n\")  #列名\n",
    "for key in wnum:\n",
    "    f.write(key[:-4]+\" \"+key[-4:]+' '+str(wnum[key])+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#中级步骤解析\n",
    "a='伊春2015.txt'\n",
    "b=a[:-4]\n",
    "print(b)\n",
    "wnum={}\n",
    "wnum[b]=19500\n",
    "print(wnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#中间步骤解析\n",
    "path2 = \"D:/python/郭峰Python讲义/数据与结果/\" #结果目录  \n",
    "name =['a1','a2','a3']\n",
    "seq=['seq11111','seqs22222','seq33333']\n",
    "f = open(path2+\"test.txt\", \"w+\")\n",
    "f.write(\"name\\tseq\\n\")   #\\t为制表符\n",
    "for i in range(0, len(name)):\n",
    "    f.write(name[i] + \"\\t\" + seq[i] + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用word进行字数统计,文件夹批量处理\n",
    "import os\n",
    "import docx\n",
    "\n",
    "path = \"D:/python/郭峰Python讲义/数据与结果/政府工作报告word/\" #文件夹目录  \n",
    "path2 = \"D:/python/郭峰Python讲义/数据与结果/\" #结果目录  \n",
    "\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "wnum={}\n",
    "for file in files:    #遍历文件夹  \n",
    "     if not os.path.isdir(file):      #判断是否是文件夹，不是文件夹才打开  \n",
    "          f = open(path+file)     #打开文件  \n",
    "          wordtest=docx.Document(path+file)    \n",
    "          a=0\n",
    "          file=file[:-5]\n",
    "          for para in wordtest.paragraphs:  #按段落统计字数\n",
    "                a=a+len(para.text)\n",
    "          else:\n",
    "                wnum[file]=a\n",
    "print(wnum)\n",
    "\n",
    "f = open(path2+\"city_wordnum2.txt\", \"w+\")  #结果读入到一个txt文件当中\n",
    "f.write(\"city\"+\" wnum\"+\"\\n\")\n",
    "for key in wnum:\n",
    "    f.write(key+\" \"+str(wnum[key])+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 格式转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为了读取doc文件，需要安装pywin32模块，非pip安装，需要下载\n",
    "#安装方式参考了下面两份网帖：\n",
    "#下载pywin32-221.win-amd64-py3.6， https://jingyan.baidu.com/article/bad08e1ed173d409c85121f8.html\n",
    "#安装过程出现bug，解决办法（部分参考，问题比帖子简单）：https://www.cnblogs.com/dbass/p/7988930.html\n",
    "#下面的程序用来安装中出现的注册表不匹配问题（反正我也看不懂）\n",
    "import sys\n",
    "\n",
    "from winreg import *\n",
    "\n",
    "# tweak as necessary\n",
    "version = sys.version[:3]\n",
    "installpath = sys.prefix\n",
    "\n",
    "regpath = \"SOFTWARE\\\\Python\\\\Pythoncore\\\\%s\\\\\" % (version)\n",
    "installkey = \"InstallPath\"\n",
    "pythonkey = \"PythonPath\"\n",
    "pythonpath = \"%s;%s\\\\Lib\\\\;%s\\\\DLLs\\\\\" % (\n",
    "    installpath, installpath, installpath\n",
    ")\n",
    "\n",
    "def RegisterPy():\n",
    "    try:\n",
    "        reg = OpenKey(HKEY_CURRENT_USER, regpath)\n",
    "    except EnvironmentError as e:\n",
    "        try:\n",
    "            reg = CreateKey(HKEY_CURRENT_USER, regpath)\n",
    "            SetValue(reg, installkey, REG_SZ, installpath)\n",
    "            SetValue(reg, pythonkey, REG_SZ, pythonpath)\n",
    "            CloseKey(reg)\n",
    "        except:\n",
    "            print(\"*** Unable to register!\")\n",
    "            return\n",
    "        print(\"--- Python\", version, \"is now registered!\")\n",
    "        return\n",
    "    if (QueryValue(reg, installkey) == installpath and\n",
    "                QueryValue(reg, pythonkey) == pythonpath):\n",
    "        CloseKey(reg)\n",
    "        print(\"=== Python\", version, \"is already registered!\")\n",
    "        return\n",
    "    CloseKey(reg)\n",
    "    print(\"*** Unable to register!\")\n",
    "    print(\"*** You probably have another Python installation!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    RegisterPy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将一个doc文档转换成docx文档\n",
    "import sys\n",
    "import pickle\n",
    "import re    #这个是正则表达式\n",
    "import codecs\n",
    "import string\n",
    "import shutil\n",
    "from win32com import client as wc\n",
    "path = \"D:/python/郭峰Python讲义/数据与结果/\" #文件夹目录  \n",
    "word = wc.Dispatch('Word.Application')\n",
    "doc = word.Documents.Open(path+'定西2011.doc')  \n",
    "doc.SaveAs(path+'定西2011.docx', 12)  # 转化后路径下的文件    \n",
    "doc.Close()\n",
    "word.Quit()\n",
    "#本程序参考了网贴：https://blog.csdn.net/X21214054/article/details/78873338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】将一个文件夹doc文档批量转换成ocx文档\n",
    "import os    \n",
    "import docx\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import codecs\n",
    "import string\n",
    "import shutil\n",
    "from win32com import client as wc\n",
    "path = \"D:/python/郭峰Python讲义/数据与结果/doc/\" #文件夹目录  \n",
    "pathn= \"D:/python/郭峰Python讲义/数据与结果/docx/\" #文件夹目录\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "for file in files:\n",
    "    word = wc.Dispatch('Word.Application')\n",
    "#    print(path+'/'+file)\n",
    "    doc = word.Documents.Open(path+'/'+file)\n",
    "    doc.SaveAs(pathn+'/'+file[:-4]+'.docx', 12)  # 转化后路径下的文件,\n",
    "    doc.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】：docx文件批量转成txt文件【存在部分格式不对的少量文档】\n",
    "import os\n",
    "import docx\n",
    "\n",
    "#教学举例\n",
    "path = \"D:/python/郭峰Python讲义/数据与结果/政府工作报告word/\" #文件夹目录  \n",
    "pathn= \"D:/python/郭峰Python讲义/数据与结果/政府工作报告txt/\" #文件夹目录\n",
    "\n",
    "#实际工作\n",
    "#path = \"D:/python/gov_report_prov/省级汇总2006_2017/\" #文件夹目录  \n",
    "#pathn= \"D:/python/gov_report_prov/省级汇总2006_2017转txt/\" #文件夹目录  \n",
    "\n",
    "#path = \"D:/python/gov_report_city/城市政府工作报告word/\" #文件夹目录  \n",
    "#pathn= \"D:/python/gov_report_city/城市政府工作报告转txt/\" #文件夹目录  \n",
    "\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "for file in files:    #遍历文件夹  \n",
    "    f = open(path+file)     #打开文件  \n",
    "    wordtest=docx.Document(path+file)    \n",
    "    fname=file[:-5]\n",
    "    for para in wordtest.paragraphs:  #按段落阅读和另存\n",
    "        try:\n",
    "            fn = open(pathn+fname+\".txt\", \"a+\",encoding='gbk')  #统计结果读入到一个txt文件当中\n",
    "            fn.write(para.text+'\\n')  #要换行\n",
    "        except:\n",
    "            fn = open(pathn+fname+\".txt\", \"a+\",encoding='utf-8')  #统计结果读入到一个txt文件当中\n",
    "            fn.write(para.text+'\\n')\n",
    "          \n",
    "    fn.close()\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 字频统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#字频统计\n",
    "\n",
    "#先定义一个函数，然后进行调用，编程经验丰富者的常用方法\n",
    "def count_chinese_word(filepath, encoding='gb2312'):\n",
    "    word_num = {}    \n",
    "    with open (filepath, 'r', encoding= encoding ,errors=\"ignore\") as txt_file:\n",
    "            for uchar in txt_file.read():\n",
    "                if is_chinese(uchar):\n",
    "                    if uchar in word_num:\n",
    "                        word_num[uchar] = word_num[uchar] + 1\n",
    "                    else:\n",
    "                        word_num[uchar] = 1\n",
    "    return word_num\n",
    "\n",
    "\n",
    "#上面的函数调用下面的函数，下面这个函数用来判断是否汉字\n",
    "#根据汉字编码在统一编码中所占的区间来标识，阿拉伯数字被排除在外了。\n",
    "\n",
    "def is_chinese(uchar):   \n",
    "    if uchar >= u'\\u4E00' and uchar <= u'\\u9FA5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "path= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "d=count_chinese_word(path+'政府工作报告2018.txt')\n",
    "d=sorted(d.items(),key=lambda t:t[1], reverse=True)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#比较两份报告字数差异，来自周耿的讲义。\n",
    "\n",
    "#先定义一个函数，然后进行调用，编程经验丰富者的常用方法\n",
    "def count_chinese_word(filepath, encoding='gb2312'):\n",
    "    word_num = {}    \n",
    "    with open (filepath, 'r', encoding= encoding ,errors=\"ignore\") as txt_file:\n",
    "            for uchar in txt_file.read():\n",
    "                if is_chinese(uchar):\n",
    "                    if uchar in word_num:\n",
    "                        word_num[uchar] = word_num[uchar] + 1\n",
    "                    else:\n",
    "                        word_num[uchar] = 1\n",
    "    return word_num\n",
    "\n",
    "\n",
    "#上面的函数调用下面的函数，下面这个函数用来判断是否汉字\n",
    "#根据汉字编码在统一编码中所占的区间来标识，阿拉伯数字被排除在外了。\n",
    "\n",
    "def is_chinese(uchar):   \n",
    "    if uchar >= u'\\u4E00' and uchar <= u'\\u9FA5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "path= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "dict1 = count_chinese_word(path+'000001_2016.txt', 'gbk')\n",
    "dict2=sorted(dict1.items(), key=lambda d: d[1], reverse=True) \n",
    "L=float(sum(dict1.values()))\n",
    "print('平安银行16年报总字数:', L)\n",
    "\n",
    "a1=[]\n",
    "a2=[]\n",
    "for (k_1,v_1) in dict2[0:100]:\n",
    "    a1.append(k_1)\n",
    "    a2.append(v_1)\n",
    "a=set(a1)  \n",
    "\n",
    "b1=[]\n",
    "b2=[] \n",
    "dict3 = count_chinese_word(path+'000002_2016.txt', 'gbk')\n",
    "dict4=sorted(dict3.items(), key=lambda d: d[1], reverse=True) \n",
    "M=float(sum(dict3.values()))\n",
    "print ('万科A16年报总字数:', M)\n",
    "for (k_2,v_2) in dict4[0:100]:\n",
    "    b1.append(k_2)\n",
    "    b2.append(v_2)\n",
    "b=set(b1)\n",
    "print ('平安银行和万科A2016年报前100高频字中的相同部分及其分别频率:' )   \n",
    "c=a&b   #求交集\n",
    "for k in c:\n",
    "    print(k,float(dict1[k]/L),float(dict3[k]/M))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 关键词提取和统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】：批量关键词数量统计,命令块格式，文件docx格式，输出一个txt文件，有近200来个样本存在问题\n",
    "import os\n",
    "import docx\n",
    "path= \"D:/python/郭峰Python讲义/数据与结果/政府工作报告word/\"\n",
    "pathn= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "keyword='债'                  #想统计什么在这里改动就行了,可以改成两个词的\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "keyword_num={}\n",
    "for file in files: \n",
    "    f = open(path+file) \n",
    "    wordtest=docx.Document(path+file)\n",
    "    a=0\n",
    "    file=file[:-5]\n",
    "    for para in wordtest.paragraphs:  #按段落统计字数,不会全文。。。\n",
    "        a=a+para.text.count(keyword)\n",
    "    else:\n",
    "        keyword_num[file]=a\n",
    "\n",
    "fn = open(pathn+\"citybaogao_keyword_num.txt\", \"w+\")  #统计结果读入到一个txt文件当中\n",
    "fn.write(\"city_year\"+\" \"+keyword+\"_num\"+\"\\n\")\n",
    "for key in keyword_num:\n",
    "    f.write(key+\" \"+str(keyword_num[key])+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】：批量关键词数量统计,命令块格式，输入txt，输出一个txt文件\n",
    "\n",
    "import os\n",
    "\n",
    "#教学案例\n",
    "#path= \"D:/python/郭峰Python讲义/数据与结果/政府工作报告/\"\n",
    "#pathn= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "\n",
    "#实际工作\n",
    "#path = \"D:/python/gov_report_city/城市政府工作报告2006_2018txt/\" #文件夹目录\n",
    "#pathn = \"D:/python/gov_report_city/\" #文件夹目录\n",
    "\n",
    "keyword='房'                  #想统计什么在这里改动就行了\n",
    "fn = open(pathn+\"citybaogao_keyword_num2.txt\", \"w+\",encoding='gbk',errors='replace')  #统计结果读入到一个txt文件当中\n",
    "fn.write(\"city_name\"+\" \"+\"year\"+\" \"+\"num\"+\"\\n\")\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "\n",
    "keyword_num=0  #没有再定义成一个字典，直接将结果存储到新的txt文档当中\n",
    "for file in files: \n",
    "    f = open(path+file,encoding='gbk',errors='replace') \n",
    "    try:\n",
    "        text=f.read()\n",
    "        file=file[:-4]\n",
    "        wordnum=text.count(keyword)\n",
    "        fn.write(str(file[:-4])+\" \"+str(file[-4:])+\" \"+str(wordnum)+\"\\n\")\n",
    "        keyword_num=keyword_num+wordnum  #统计这个词累计出现了多少次\n",
    "    except:\n",
    "        print(file)\n",
    "    f.close()\n",
    "fn.close()\n",
    "print(keyword_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a='这两天雾霾很严重'\n",
    "b=a.index('雾')\n",
    "print(a[a.index('雾'):a.index('雾')+len('雾霾')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】：关键词前后一定字数提取，命令块格式，文件docx格式，输出一个txt文件\n",
    "import os\n",
    "import docx\n",
    "\n",
    "#教学案例\n",
    "path= \"D:/python/郭峰Python讲义/数据与结果/政府工作报告word/\"\n",
    "pathn= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "\n",
    "#实际工作\n",
    "#path = \"D:/python/gov_report_city/城市政府工作报告word/\" #文件夹目录\n",
    "#pathn = \"D:/python/gov_report_city/\" #文件夹目录\n",
    "\n",
    "keyword='债'                  #想统计什么在这里改动就行了，也可以改造成函数形式\n",
    "wn=10  #关键词前后10个字提取出来\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "keyword_nearby={}\n",
    "for file in files: \n",
    "    f = open(path+\"/\"+file) \n",
    "    wordtest=docx.Document(path+\"/\"+file)\n",
    "    a=\"\"\n",
    "    file=file[:-5]\n",
    "    for para in wordtest.paragraphs:  #按段落统计字数,不会全文。。。\n",
    "        for item in enumerate(para.text):\n",
    "#            para.text.replace(u'\\xa0', u' ') \n",
    "            if item[1] == keyword:\n",
    "                _index=item[0] \n",
    "                a=a+\"   \"+para.text[_index-wn:_index+wn+1]\n",
    "    else:\n",
    "#        a.encode('gbk','ignore')\n",
    "         a=a.replace(u'\\xa0', u' ')\n",
    "         a=a.replace(u'\\ue004',u'')\n",
    "         keyword_nearby[file]=a\n",
    "f = open(pathn+\"citybaogao_keyword_nearby.txt\", \"w+\")  #统计结果读入到一个txt文件当中\n",
    "f.write(\"city_year\"+\" \"+keyword+\"_nearby\"+\"\\n\")\n",
    "for key in keyword_nearby:\n",
    "    f.write(key+\" \"+str(keyword_nearby[key])+\"\\n\")\n",
    "f.close()\n",
    "\n",
    "#注：\n",
    "#这个程序处理了一个 'gbk' codec can't encode character '\\xa0' in position 22，解决过程非常麻烦\n",
    "#尝试了 f = open(\"citybaogao_keyword_nearby.txt\", \"w+\",encoding='utf-8')方法，失败\n",
    "#尝试了 a.encode('gbk','ignore')的方法，失败\n",
    "#最终使用a=a.replace(u'\\xa0', u' ') 的方法将问题解决，但导致输出的文档中，存在少量的乱码\n",
    "#更重要的是，涉及到大量的不识别字符，总不能一一替代。\n",
    "#编码问题是一个非常讨厌的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实例操作】2018年政府工作报告，删除无用的东西\n",
    "import os    \n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import codecs\n",
    "import string\n",
    "import shutil\n",
    "path='D:/python/gov_report_prov/2018/' #2018年原始文件存在即是utf8的格式，又是gbk格式\n",
    "pathn='D:/python/gov_report_prov/2018new/'\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称\n",
    "#print(files)  #这是一个列表\n",
    "\n",
    "for file in files:\n",
    "    f=open(path+str(file),encoding='gbk')\n",
    "    try:\n",
    "        text=f.read()   #个别文件存在乱码 ，所以跳过去\n",
    "    except:\n",
    "        continue\n",
    "    text=text.replace('<span style=\"font-size: 14px;\">','')\n",
    "    fn=open(pathn+str(file),'w+',encoding='utf-8')\n",
    "    fn.write(text)\n",
    "    f.close()\n",
    "    os.remove(path+str(file))  #修改一个，删除一个，这样留下来的文件就好弄了\n",
    "    fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】挑出一系列关键词所在的句子,不重复出现。\n",
    "import re\n",
    "import os\n",
    "\n",
    "#教学案例\n",
    "path= \"D:/python/郭峰Python讲义/数据与结果/政府工作报告/\"\n",
    "pathn= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "\n",
    "#实际工作\n",
    "#path = \"D:/python/gov_report_city/城市政府工作报告2006_2018txt/\" #文件夹目录\n",
    "#pathn = \"D:/python/gov_report_city/\" #文件夹目录\n",
    "\n",
    "#keywords=['债','城投','融资平台'] #城投债论文\n",
    "keywords=['金融','信贷','贷款','融资','债券','集资','借贷','上市','银行','证券','信托','私募','股权基金'] #学生毕业论文\n",
    "length=len(keywords)\n",
    "keywordnum=0\n",
    "fn = open(pathn+\"keywordnearby.txt\", \"w+\",encoding='gbk',errors='replace') \n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "for file in files: \n",
    "    fn.write(str('\\n'+file[:-8]+'*'+file[-8:-4]+'*'))\n",
    "    f = open(path+file,'r',encoding='gbk',errors='replace') \n",
    "    text=f.read()\n",
    "    g = re.split(r\"[，。？；,.]\", text) #根据文章中的实际情况添加分割句子的标点，这是一个正则表达式\n",
    "    for line in g:\n",
    "        for i in range(length):\n",
    "            if re.match('.*'+keywords[i]+'.*',line):    #这也是一个正则表达式\n",
    "                if i==0:\n",
    "                    line=line.replace('\\n','')  #删除换行\n",
    "                    line=line.strip()  #删除空格\n",
    "                    fn.write(line+'*')\n",
    "                    keywordnum=keywordnum+1\n",
    "                else:\n",
    "                    continue\n",
    "                for j in range(i):\n",
    "                    if re.match('.*'+keywords[j]+'.*',line):  #这是为了避免重复统计\n",
    "                        continue\n",
    "                    else:\n",
    "                        line=line.replace('\\n','')  #删除换行\n",
    "                        line=line.strip()  #删除空格\n",
    "                        fn.write(line+'*')\n",
    "                        keywordnum=keywordnum+1\n",
    "            else:\n",
    "                continue\n",
    "    f.close()\n",
    "fn.close()\n",
    "print(keywordnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5  文本编码格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "政府工作报\n",
      "（云南省）\n",
      "2018年\n",
      "（北京市）\n",
      "2018年\n",
      "（四川省）\n",
      "天津市20\n",
      "（宁夏）2\n",
      "（安徽省）\n",
      "（山东省）\n",
      "（山西省）\n",
      "（广东省）\n",
      "广西壮族自\n",
      "（新疆）2\n",
      "（江苏省）\n",
      "2018年\n",
      "（河北省）\n",
      "（河南省）\n",
      "（浙江省）\n",
      "（海南省）\n",
      "政府工作报\n",
      "2018年\n",
      "（甘肃省）\n",
      "（福建省）\n",
      "2018西\n",
      "（贵州省）\n",
      "（辽宁省）\n",
      "2018年\n",
      "（陕西省）\n",
      "（青海省）\n",
      "（黑龙江）\n"
     ]
    }
   ],
   "source": [
    "#字符编码（Character Encoding）是将字符集中的字符码映射为字节流的一种具体实现方案\n",
    "#常见的字符编码有 ASCII 编码、UTF-8 编码、GBK 编码等。\n",
    "#gbk或gbk2312可以用来处理中文\n",
    "#我一般将编码格式设置为utf-8\n",
    "#不同电脑默认的编码方式可能不同，所以有时候需要调整\n",
    "#关于python编码的详细介绍:https://www.cnblogs.com/Jedore/p/7052994.html\n",
    "\n",
    "#【实际应用】批量修改文件的编码格式\n",
    "import os \n",
    "path='D:/python/郭峰Python讲义/数据与结果/省级政府工作报告2018编码混杂/'\n",
    "path2='D:/python/郭峰Python讲义/数据与结果/省级政府工作报告2018编码清理/'\n",
    "\n",
    "files= os.listdir(path)\n",
    "for file in files:\n",
    "    oldpath=os.path.join(path,file)\n",
    "    try:\n",
    "        f1=open(path+file, 'r',encoding='utf8')  \n",
    "        content = f1.read()\n",
    "    except:\n",
    "        #continue  #通过添加这个continue可以不执行下面两行命令，进而看到到底是哪些文件是utf8编码的\n",
    "        f1=open(path+file,'r')\n",
    "        content = f1.read()\n",
    "    print(content[0:5])\n",
    "    f2=open(path2+file,'w',encoding='utf8')\n",
    "    f2.write(content)\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "#其他批量调整的方法：\n",
    "#https://blog.csdn.net/oh5W6HinUg43JvRhhB/article/details/80681661"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 jieba中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jieba 模块的安装 pip模式,WinPython Command Prompt,管理员模式打开， pip install jieba \n",
    "# jieba的安装费了非常大的力气，最终换了一个安装盘，从c改成d，居然问题就解决了，到底啥原因也没搞明白\n",
    "# jieba支持多种分词方式，具体对比如下\n",
    "import jieba \n",
    "seg1 = jieba.cut(\"我来到南京大学上课\") # 默认精确模式，这个用来统计词频率\n",
    "seg2 = jieba.cut_for_search(\"我来到南京大学上课\") #搜索引擎模式\n",
    "seg3 = jieba.cut(\"我来到南京大学上课\", cut_all=True) # 全模式\n",
    "print(','.join(seg1))\n",
    "print(','.join(seg2))\n",
    "print(','.join(seg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分析一份报告出现的中文词汇频率，包含数字、标点等\n",
    "import jieba\n",
    "from collections import Counter\n",
    "path= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "with open (path+\"000002_2016.txt\", 'r', encoding= 'gbk' ,errors=\"ignore\") as file:\n",
    "    data=file.read()\n",
    "cut = jieba.cut(data)\n",
    "data = dict(Counter(cut))\n",
    "y=sorted(data.items(), key=lambda d:d[1], reverse = True )\n",
    "print(y)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分析两份报告的中文词汇频率的交集，即包含的共同高频词汇，剔除了数字、标点，以及一个单字词\n",
    "import jieba\n",
    "from collections import Counter\n",
    "path= \"D:/python/郭峰Python讲义/数据与结果/\" \n",
    "\n",
    "with open (path+\"000001_2016.txt\", 'r', encoding= 'gbk' ,errors=\"ignore\") as file:\n",
    "    data=file.read()\n",
    "cut = jieba.cut(data)\n",
    "data1 = dict(Counter(cut))\n",
    "data11=data1.copy()\n",
    "for i in data1:\n",
    "    if len(i)<2 or data1[i]<10:\n",
    "        data11.pop(i)\n",
    "with open (path+\"000002_2016.txt\", 'r', encoding= 'gbk' ,errors=\"ignore\") as file:\n",
    "    data=file.read()\n",
    "cut = jieba.cut(data)\n",
    "data2 = dict(Counter(cut))\n",
    "data22=data2.copy()\n",
    "for i in data2:\n",
    "    if len(i)<2 or data2[i]<10:\n",
    "        data22.pop(i)\n",
    "k1=data11.keys()\n",
    "k2=data22.keys()\n",
    "k3=k1&k2\n",
    "print(k3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网上找到一个，可以求一个文本的“摘要”，还不知道能在什么上面可以用到\n",
    "#先要安装：pip install snownlp\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "text1 = u\"美媒称，鉴于全球石油市场过度供给的情况，中国原油需求下滑是其首要担忧之一。过量生产拉低了石油价格，但是中国过去一年左右的疲弱需求引发了缓慢的回弹。\"\n",
    "\n",
    "s = SnowNLP(text1)\n",
    "\n",
    "print(s.summary(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】将“省*年份”报告中关于环保的表述片段合成一个文档，然后统计词频，并标注词性\n",
    "import jieba \n",
    "import os\n",
    "from collections import Counter\n",
    "import jieba.posseg as pseg\n",
    "import pandas as pd\n",
    "\n",
    "#实际工作\n",
    "path = \"D:/python/gov_report_prov/data_huanbao/\" #文件夹目录\n",
    "pathn = \"D:/python/gov_report_prov/\" \n",
    "\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称  \n",
    "\n",
    "f_total = open(pathn+\"huanbao_total.txt\", \"w+\",encoding='gbk',errors='replace')  #统计结果读入到一个txt文件当中\n",
    "for file in files: \n",
    "    if int(file[-8:-4])<2008:  #2008年后和2008年年前的文件编码格式不一样\n",
    "        f = open(path+file,encoding='gbk',errors='replace') \n",
    "    else:\n",
    "        f = open(path+file,encoding='utf-8',errors='replace') \n",
    "    try:\n",
    "        text=f.read()\n",
    "        text=text.replace('\\n','')\n",
    "        text=text.replace(' ','')\n",
    "        f_total.write(file[0:-4]+'\\n')\n",
    "        f_total.write(text+\"\\n\")\n",
    "    except:\n",
    "        print(file)\n",
    "    f.close()\n",
    "f_total.close()\n",
    "\n",
    "word_list=[]\n",
    "flag_list=[]\n",
    "\n",
    "df1=pd.DataFrame(columns=['word','type']) \n",
    "\n",
    "f_total = open(pathn+\"huanbao_total.txt\", \"r\",encoding='gbk',errors='replace') \n",
    "text=f_total.read()\n",
    "words = pseg.cut(text) # 默认精确模式，这个用来统计词频率\n",
    "for word,flag in words:\n",
    "    word_list.append(word)\n",
    "    flag_list.append(flag)  #标注词性\n",
    "    \n",
    "df1['word']=word_list \n",
    "df1['type']=flag_list\n",
    "df3=df1.groupby(['word','type']).size()\n",
    "df3.to_csv(pathn+\"huanbao_cut.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【实战操作】统计文档字数，对某些重要的单词，进行赋值加权,应用在环保口号研究中\n",
    "import re\n",
    "import os\n",
    "\n",
    "#实际工作\n",
    "path = \"D:/python/gov_report_prov/data_huanbao/\" #文件夹目录\n",
    "pathn = \"D:/python/gov_report_prov/\" \n",
    "\n",
    "\n",
    "fq1 = open(pathn+'赋权1.txt',encoding='gbk',errors='replace')\n",
    "fq1=fq1.read()\n",
    "keyword1=fq1.split('\\n')\n",
    "fq2 = open(pathn+'赋权2.txt',encoding='gbk',errors='replace')\n",
    "fq2=fq2.read()\n",
    "keyword2=fq2.split('\\n')\n",
    "\n",
    "word_num = open(pathn+\"word_num.txt\", \"w+\",encoding='gbk',errors='replace') \n",
    "word_num.write('prov_name'+' '+'year'+' '+'word_num1'+' '+'word_num2'+' '+'word_num3'+' '+'word_num4'+' '+'keynum1'+' '+'keynum2'+'\\n')\n",
    "\n",
    "files= os.listdir(path)  #得到文件夹下的所有文件名称\n",
    "for file in files: \n",
    "    if int(file[-8:-4])<2008:               #苹果和联想两台电脑处理的数据，编码不一样\n",
    "        f = open(path+file,encoding='gbk',errors='replace') \n",
    "    else:\n",
    "        f = open(path+file,encoding='utf-8',errors='replace')  \n",
    "    try:\n",
    "        text=f.read()\n",
    "        text=text.replace('\\n','')\n",
    "        text=text.replace(' ','')\n",
    "        wordn1=len(text)                    #直接进行字数统计\n",
    "        g = re.split(r\"[，。？；,.]\", text)   #根据文章中的实际情况添加分割句子的标点\n",
    "        wordn2=len(g)-1 \n",
    "        wordn3=len(g)-1                    #如果从0开始计数，则会少了一些标点符号\n",
    "        wordn4=len(g)-1\n",
    "        keynum1=0\n",
    "        keynum2=0\n",
    "        for line in g:\n",
    "            line=line.strip()                #删除空格\n",
    "            wordn2=wordn2+len(line)          #逐行统计字数，与全文直接统计字数，略有差异\n",
    "            a=0\n",
    "            for k in keyword1:\n",
    "                if re.match('.*'+k+'.*',line): \n",
    "                    wordn3=wordn3+len(line)*1   #额外增加0.5倍数\n",
    "                    keynum1=keynum1+1\n",
    "                else:\n",
    "                    continue\n",
    "            for k2 in keyword2:\n",
    "                if re.match('.*'+k2+'.*',line): \n",
    "                    wordn4=wordn3-len(line)*0.5  #额外减少0.5倍数\n",
    "                    keynum2=keynum2+1\n",
    "                else:\n",
    "                    continue\n",
    "            wordn3=wordn3+len(line)\n",
    "            wordn4=wordn4+len(line)\n",
    "    except:\n",
    "        print(file)   #如果有没能成功读出的文档，则显示是那一篇（没有这种情形）\n",
    "    word_num.write(file[0:-8]+' '+file[-8:-4]+' '+str(wordn1)+' '+str(wordn2)+' '+str(wordn3)+' '+str(wordn4)+' '+str(keynum1)+' '+str(keynum2)+'\\n')\n",
    "    f.close()\n",
    "word_num.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本讲结束，下一将：网络爬虫入门"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
